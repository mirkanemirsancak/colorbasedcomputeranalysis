{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vyEuA1jMBBZE"
      },
      "source": [
        "DRIVE INTEGRATION\n",
        "\n",
        "This algorithm was developed on Google Colaboratory to work with an online GPU system to show this algorithm can be used by anyone around the world who wants to apply for their laboratory. Therefore, Google Drive was mounted for the first step. Also, for the next steps, some parts of the code can be differentiate if anyone who wants to run on their local host. To run this algorithm on your local, please change path and other importing styles."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0W2Zt5Nf76MJ",
        "outputId": "aa933ccc-8b55-48af-89ca-7190895f99e7"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CJuOHHzlsSYH"
      },
      "source": [
        "COMPUTER VISION BASED ROI SEGMENTATION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "hM_Z6SpM3clR",
        "outputId": "a0a52f67-d6c3-494b-b73c-bf4384660953"
      },
      "outputs": [],
      "source": [
        "!pip install ultralytics\n",
        "import os\n",
        "import cv2\n",
        "import torch\n",
        "from ultralytics import YOLO\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load YOLOv8 model\n",
        "model = YOLO('/content/drive/MyDrive/visual titration/v2/yolo/data/runs3/weights/best.pt')\n",
        "\n",
        "# Folder containing images\n",
        "image_folder = '/content/drive/MyDrive/visual titration/v8/12122024_newdataset'\n",
        "image_files = [f for f in os.listdir(image_folder) if f.endswith('.jpg')]\n",
        "\n",
        "# Folder to save cropped images after segmentation\n",
        "output_folder = '/content/drive/MyDrive/visual titration/v8/data/segmented_12122024_newdataset'\n",
        "os.makedirs(output_folder, exist_ok=True)  # Create the folder if it doesn't exist\n",
        "\n",
        "# Process segmentation results for all images\n",
        "for image_file in image_files:\n",
        "    # Get the full path of the image file\n",
        "    image_path = os.path.join(image_folder, image_file)\n",
        "\n",
        "    # Read the image\n",
        "    image = cv2.imread(image_path)\n",
        "\n",
        "    # Perform segmentation using YOLOv8 model\n",
        "    results = model.predict(image)\n",
        "\n",
        "    # Print segmentation results\n",
        "    print(f\"Segmentation Results - {image_file}:\")\n",
        "\n",
        "    # Process results and apply masks\n",
        "    for idx, result in enumerate(results):\n",
        "        # Extract the cropped region based on the segmentation mask\n",
        "        if result.boxes is not None:\n",
        "            for i, box in enumerate(result.boxes.xyxy):\n",
        "                x1, y1, x2, y2 = map(int, box)  # Extract bounding box coordinates\n",
        "                cropped_img = image[y1:y2, x1:x2]  # Get the cropped area\n",
        "\n",
        "                # Save the cropped image\n",
        "                cropped_filename = os.path.join(output_folder, f\"{os.path.splitext(image_file)[0]}_crop_{i}.jpg\")\n",
        "                cv2.imwrite(cropped_filename, cropped_img)\n",
        "\n",
        "                print(f\"Segmented area saved: {cropped_filename}\")\n",
        "\n",
        "                # Optionally display the masked image\n",
        "                masked_image = result.plot()\n",
        "                plt.imshow(cv2.cvtColor(masked_image, cv2.COLOR_BGR2RGB))\n",
        "                plt.axis('off')  # Hide axes\n",
        "                plt.title(f'Segmented Area - {image_file}')\n",
        "                plt.show()  # Display the masked image\n",
        "\n",
        "# *** For details, contact the repository owner (Mirkan Emir Sancak, mrkn.sancak@gmail.com)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qo8Fk2QUBGWa"
      },
      "source": [
        "AVERAGE HSV VALUATION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "40InPYkYXj3F",
        "outputId": "1fee3023-17ca-4fc6-89ac-a8bf3849dcec"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "def get_min_max_hsv(image, mask=None):\n",
        "    \"\"\"\n",
        "    Calculates the minimum and maximum HSV values of a specific region in the image (defined by a mask).\n",
        "\n",
        "    :param image: Image in BGR format\n",
        "    :param mask: Optional mask. Only the masked region will be analyzed.\n",
        "    :return: HSV min and max values (h_min, s_min, v_min, h_max, s_max, v_max)\n",
        "    \"\"\"\n",
        "    # Convert the image to HSV format\n",
        "    hsv_image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
        "\n",
        "    if mask is not None:\n",
        "        # Select the masked region\n",
        "        hsv_values = hsv_image[mask > 0]\n",
        "    else:\n",
        "        # Use the entire image\n",
        "        hsv_values = hsv_image.reshape((-1, 3))\n",
        "\n",
        "    # Calculate the minimum and maximum values for each channel (H, S, V)\n",
        "    h_min, s_min, v_min = np.min(hsv_values[:, 0]), np.min(hsv_values[:, 1]), np.min(hsv_values[:, 2])\n",
        "    h_max, s_max, v_max = np.max(hsv_values[:, 0]), np.max(hsv_values[:, 1]), np.max(hsv_values[:, 2])\n",
        "\n",
        "    return int(h_min), int(s_min), int(v_min), int(h_max), int(s_max), int(v_max)\n",
        "\n",
        "# Folder containing images\n",
        "image_folder = '/content/drive/MyDrive/visual titration/v8/data/segmented_12122024_newdataset'\n",
        "image_files = [f for f in os.listdir(image_folder) if f.endswith('.jpg')]\n",
        "\n",
        "# Perform HSV analysis for all images\n",
        "for image_file in image_files:\n",
        "    # Get the full path of the image file\n",
        "    image_path = os.path.join(image_folder, image_file)\n",
        "\n",
        "    # Load the image\n",
        "    image = cv2.imread(image_path)\n",
        "    if image is None:\n",
        "        print(f\"Error loading image: {image_file}\")\n",
        "        continue\n",
        "\n",
        "    # Create a mask - Define the region of interest (example dimensions, adjust as needed)\n",
        "    mask = np.zeros(image.shape[:2], dtype=np.uint8)\n",
        "    mask[***] = 255  # Define the area of interest\n",
        "\n",
        "    # Find Min and Max HSV values for the masked region\n",
        "    h_min, s_min, v_min, h_max, s_max, v_max = get_min_max_hsv(image, mask)\n",
        "\n",
        "    # Print Min and Max HSV values\n",
        "    print(f\"HSV Min Values - {image_file}: H = {h_min}, S = {s_min}, V = {v_min}\")\n",
        "    print(f\"HSV Max Values - {image_file}: H = {h_max}, S = {s_max}, V = {v_max}\")\n",
        "\n",
        "# *** For details, contact the repository owner (Mirkan Emir Sancak, mrkn.sancak@gmail.com)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VeeRAPdmsnwe"
      },
      "source": [
        "HSV BASED SEGMENTATION OF ROI-REGION OF INTEREST"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "68BfUa0MaDfj",
        "outputId": "2a1210a0-d0f5-4ba5-a269-17ea125a788c"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# Function: Calculate global HSV values from the entire image\n",
        "def get_global_hsv_range(image):\n",
        "    hsv_image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
        "    hsv_values = hsv_image.reshape((-1, 3))\n",
        "    h_min, s_min, v_min = np.min(hsv_values[:, 0]), np.min(hsv_values[:, 1]), np.min(hsv_values[:, 2])\n",
        "    h_max, s_max, v_max = np.max(hsv_values[:, 0]), np.max(hsv_values[:, 1]), np.max(hsv_values[:, 2])\n",
        "    return int(h_min), int(s_min), int(v_min), int(h_max), int(s_max), int(v_max)\n",
        "\n",
        "# Function: Calculate new HSV range to reduce pixel count by 20%\n",
        "def adjust_hsv_range(image, h_min, s_min, v_min, h_max, s_max, v_max):\n",
        "    hsv_image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
        "    hsv_values = hsv_image.reshape((-1, 3))\n",
        "\n",
        "    # Compute histogram\n",
        "    h_hist, _ = np.histogram(hsv_values[:, 0], bins=180, range=(0, 180))\n",
        "    s_hist, _ = np.histogram(hsv_values[:, 1], bins=256, range=(0, 256))\n",
        "    v_hist, _ = np.histogram(hsv_values[:, 2], bins=256, range=(0, 256))\n",
        "\n",
        "    # Target 80% of pixel count\n",
        "    total_pixels = hsv_values.shape[0]\n",
        "    target_pixels = int(total_pixels * 0.8)\n",
        "\n",
        "    # Limit H channel\n",
        "    h_cumsum = np.cumsum(h_hist)\n",
        "    h_min_new = np.searchsorted(h_cumsum, total_pixels - target_pixels)\n",
        "    h_max_new = np.searchsorted(h_cumsum, target_pixels)\n",
        "\n",
        "    # Limit S channel\n",
        "    s_cumsum = np.cumsum(s_hist)\n",
        "    s_min_new = np.searchsorted(s_cumsum, total_pixels - target_pixels)\n",
        "    s_max_new = np.searchsorted(s_cumsum, target_pixels)\n",
        "\n",
        "    # Limit V channel\n",
        "    v_cumsum = np.cumsum(v_hist)\n",
        "    v_min_new = np.searchsorted(v_cumsum, total_pixels - target_pixels)\n",
        "    v_max_new = np.searchsorted(v_cumsum, target_pixels)\n",
        "\n",
        "    return h_min_new, s_min_new, v_min_new, h_max_new, s_max_new, v_max_new\n",
        "\n",
        "# Folder containing images\n",
        "image_folder = '/content/drive/MyDrive/visual titration/v8/data/segmented_12122024_newdataset'\n",
        "image_files = [f for f in os.listdir(image_folder) if f.endswith('.jpg')]\n",
        "\n",
        "# Create DataFrame to store results for the Excel file\n",
        "df_results = pd.DataFrame(columns=['Image', 'H_min', 'S_min', 'V_min', 'H_max', 'S_max', 'V_max'])\n",
        "\n",
        "# Folder to save masked images\n",
        "output_folder = '/content/drive/MyDrive/visual titration/v8/data/masked_segmented_12122024_newdataset'\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "# Perform HSV analysis for all images\n",
        "for image_file in image_files:\n",
        "    # Get the full path of the image file\n",
        "    image_path = os.path.join(image_folder, image_file)\n",
        "\n",
        "    # Load the image\n",
        "    image = cv2.imread(image_path)\n",
        "    if image is None:\n",
        "        print(f\"Error loading image: {image_file}\")\n",
        "        continue\n",
        "\n",
        "    # Step 1: Find global HSV values\n",
        "    h_min, s_min, v_min, h_max, s_max, v_max = get_global_hsv_range(image)\n",
        "\n",
        "    # Step 2: Compute new HSV ranges (80% pixel segmentation)\n",
        "    h_min_new, s_min_new, v_min_new, h_max_new, s_max_new, v_max_new = adjust_hsv_range(\n",
        "        image, h_min, s_min, v_min, h_max, s_max, v_max\n",
        "    )\n",
        "\n",
        "    # Add new row to DataFrame\n",
        "    new_row = pd.DataFrame({\n",
        "        'Image': [image_file],\n",
        "        'H_min': [h_min_new],\n",
        "        'S_min': [s_min_new],\n",
        "        'V_min': [v_min_new],\n",
        "        'H_max': [h_max_new],\n",
        "        'S_max': [s_max_new],\n",
        "        'V_max': [v_max_new]\n",
        "    })\n",
        "    df_results = pd.concat([df_results, new_row], ignore_index=True)\n",
        "\n",
        "    # Mask the image based on the obtained HSV range\n",
        "    lower = np.array([h_min_new, s_min_new, v_min_new])\n",
        "    upper = np.array([h_max_new, s_max_new, v_max_new])\n",
        "    hsv_image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
        "    mask_hsv = cv2.inRange(hsv_image, lower, upper)\n",
        "    result = cv2.bitwise_and(image, image, mask=mask_hsv)\n",
        "\n",
        "    # Save the masked image\n",
        "    output_image_path = os.path.join(output_folder, f\"masked_{image_file}\")\n",
        "    cv2.imwrite(output_image_path, result)\n",
        "\n",
        "    # Display the masked image (optional)\n",
        "    cv2_imshow(result)  # Using cv2_imshow instead of cv2.imshow\n",
        "\n",
        "# Save results to an Excel file\n",
        "output_excel_path = '/content/drive/MyDrive/visual titration/v8/data/hsvcodes_masked_segmented_12122024_newdataset.xlsx'\n",
        "df_results.to_excel(output_excel_path, index=False)\n",
        "\n",
        "print(f\"HSV analysis results have been saved to the Excel file: {output_excel_path}\")\n",
        "print(f\"Masked images have been saved in the folder: {output_folder}\")\n",
        "\n",
        "# *** For details, contact the repository owner (Mirkan Emir Sancak, mrkn.sancak@gmail.com)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uu7KxQVVs4-E"
      },
      "source": [
        "IMAGE PROCESSING AND SUMMARY"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "irHhm4jlzFPi",
        "outputId": "e38f0955-a2f8-4fe7-f0b0-01a70c8d9b77"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "# Path to the Excel file containing HSV ranges\n",
        "hsv_excel_path = '/content/drive/MyDrive/visual titration/v8/data/hsvcodes_masked_segmented_12122024_newdataset.xlsx'\n",
        "\n",
        "# Load the HSV ranges from the Excel file\n",
        "hsv_df = pd.read_excel(hsv_excel_path)\n",
        "\n",
        "# Create a DataFrame to store the results\n",
        "df_results = pd.DataFrame(columns=['Image', 'Total_Pixels', 'Pixel_Percentage',\n",
        "                                   'Mean_R', 'Std_R', 'Mean_G', 'Std_G', 'Mean_B', 'Std_B',\n",
        "                                   'Mean_H', 'Std_H', 'Mean_S', 'Std_S', 'Mean_V', 'Std_V',\n",
        "                                   'Mean_L', 'Std_L', 'Mean_A', 'Std_A', 'Mean_B_LAB', 'Std_B_LAB'])\n",
        "\n",
        "# Folder containing the images\n",
        "image_folder = '/content/drive/MyDrive/visual titration/v8/data/masked_segmented_12122024_newdataset'\n",
        "image_files = [f for f in os.listdir(image_folder) if f.endswith('.jpg') or f.endswith('.png')]\n",
        "\n",
        "# Process each image\n",
        "for image_file in image_files:\n",
        "    try:\n",
        "        # Construct the full image path\n",
        "        image_path = os.path.join(image_folder, image_file)\n",
        "\n",
        "        # Load the image\n",
        "        image = cv2.imread(image_path)\n",
        "\n",
        "        # Skip if the image cannot be loaded\n",
        "        if image is None:\n",
        "            print(f\"Error loading image: {image_file}\")\n",
        "            continue\n",
        "\n",
        "        # Remove the 'masked_' prefix to match the Excel file\n",
        "        corresponding_image_name = image_file.replace('masked_', '')\n",
        "\n",
        "        # Get the HSV ranges for the current image from the Excel file\n",
        "        hsv_row = hsv_df[hsv_df['Image'].str.contains(corresponding_image_name, na=False, case=False)]\n",
        "\n",
        "        # Skip if no HSV data is found for the image\n",
        "        if hsv_row.empty:\n",
        "            print(f\"No HSV data found for image: {image_file}\")\n",
        "            continue\n",
        "\n",
        "        # Extract HSV ranges\n",
        "        h_min, s_min, v_min, h_max, s_max, v_max = hsv_row[['H_min', 'S_min', 'V_min', 'H_max', 'S_max', 'V_max']].values[0]\n",
        "\n",
        "        # Resize the image\n",
        "        scale_percent = ***\n",
        "        width = int(image.shape[1] * scale_percent / 100)\n",
        "        height = int(image.shape[0] * scale_percent / 100)\n",
        "        scaled_image = cv2.resize(image, (width, height))\n",
        "\n",
        "        # *** For details, contact the repository owner (Mirkan Emir Sancak, mrkn.sancak@gmail.com)\n",
        "\n",
        "        # Step 1: Apply Sobel Filter for Edge Detection\n",
        "        sobel_x = cv2.Sobel(scaled_image, cv2.CV_64F, 1, 0, ksize=***)\n",
        "        sobel_y = cv2.Sobel(scaled_image, cv2.CV_64F, 0, 1, ksize=***)\n",
        "        edges = cv2.magnitude(sobel_x, sobel_y)\n",
        "        edges = np.uint8(edges)\n",
        "\n",
        "        # Step 2: Remove Reflections\n",
        "        hsv_image = cv2.cvtColor(scaled_image, cv2.COLOR_BGR2HSV)\n",
        "        reflection_mask = cv2.inRange(hsv_image, np.array([0, 0, 200]), np.array([180, 255, 255]))  # Detect bright regions\n",
        "        cleaned_image = cv2.inpaint(scaled_image, reflection_mask, inpaintRadius=3, flags=cv2.INPAINT_TELEA)\n",
        "\n",
        "        # Step 3: Enhance Contrast with CLAHE\n",
        "        lab_image = cv2.cvtColor(cleaned_image, cv2.COLOR_BGR2LAB)\n",
        "        l, a, b = cv2.split(lab_image)\n",
        "        clahe = cv2.createCLAHE(clipLimit=***, tileGridSize=(8, 8))\n",
        "        l = clahe.apply(l)\n",
        "        lab_image = cv2.merge((l, a, b))\n",
        "        enhanced_image = cv2.cvtColor(lab_image, cv2.COLOR_LAB2BGR)\n",
        "\n",
        "        # Step 4: Adaptive Thresholding\n",
        "        gray_image = cv2.cvtColor(enhanced_image, cv2.COLOR_BGR2GRAY)\n",
        "        adaptive_mask = cv2.adaptiveThreshold(gray_image, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2)\n",
        "\n",
        "        # Step 5: Bilateral Filtering\n",
        "        bilateral_filtered = cv2.bilateralFilter(enhanced_image, 9, 75, 75)\n",
        "\n",
        "        # Create a mask to exclude black pixels (assuming black is [0, 0, 0] in BGR)\n",
        "        black_mask = cv2.inRange(bilateral_filtered, np.array([1, 1, 1]), np.array([255, 255, 255]))\n",
        "\n",
        "        # Apply the mask to the image\n",
        "        masked_image = cv2.bitwise_and(bilateral_filtered, bilateral_filtered, mask=black_mask)\n",
        "\n",
        "        # Calculate the number of non-black pixels\n",
        "        non_black_pixels = cv2.countNonZero(cv2.cvtColor(masked_image, cv2.COLOR_BGR2GRAY))\n",
        "        total_pixels = scaled_image.shape[0] * scaled_image.shape[1]\n",
        "        pixel_percentage = (non_black_pixels / total_pixels) * 100\n",
        "\n",
        "        # Compute color statistics\n",
        "        mean_rgb, std_rgb = np.mean(masked_image, axis=(0, 1)), np.std(masked_image, axis=(0, 1))\n",
        "        mean_hsv, std_hsv = np.mean(hsv_image, axis=(0, 1)), np.std(hsv_image, axis=(0, 1))\n",
        "        mean_lab, std_lab = np.mean(lab_image, axis=(0, 1)), np.std(lab_image, axis=(0, 1))\n",
        "\n",
        "        # Add results to the DataFrame\n",
        "        df_results = pd.concat([df_results, pd.DataFrame({\n",
        "            'Image': [image_file],\n",
        "            'Total_Pixels': [total_pixels],\n",
        "            'Pixel_Percentage': [pixel_percentage],\n",
        "            'Mean_R': [mean_rgb[2]], 'Std_R': [std_rgb[2]],\n",
        "            'Mean_G': [mean_rgb[1]], 'Std_G': [std_rgb[1]],\n",
        "            'Mean_B': [mean_rgb[0]], 'Std_B': [std_rgb[0]],\n",
        "            'Mean_H': [mean_hsv[0]], 'Std_H': [std_hsv[0]],\n",
        "            'Mean_S': [mean_hsv[1]], 'Std_S': [std_hsv[1]],\n",
        "            'Mean_V': [mean_hsv[2]], 'Std_V': [std_hsv[2]],\n",
        "            'Mean_L': [mean_lab[0]], 'Std_L': [std_lab[0]],\n",
        "            'Mean_A': [mean_lab[1]], 'Std_A': [std_lab[1]],\n",
        "            'Mean_B_LAB': [mean_lab[2]], 'Std_B_LAB': [std_lab[2]]\n",
        "        })], ignore_index=True)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing image {image_file}: {e}\")\n",
        "\n",
        "# Save the results to an Excel file\n",
        "output_excel_path = '/content/drive/MyDrive/visual titration/v8/data/colorspaces_masked_segmented_12122024_newdataset.xlsx'\n",
        "df_results.to_excel(output_excel_path, index=False)\n",
        "\n",
        "print(f\"Analysis results saved to Excel file: {output_excel_path}\")\n",
        "\n",
        "# *** For details, contact the repository owner (Mirkan Emir Sancak, mrkn.sancak@gmail.com)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "1aAETop68FeX",
        "outputId": "8f0b51ef-52f5-4fe3-b996-c062cb32fa35"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the dataset from the Excel file\n",
        "data_path = '/content/drive/MyDrive/visual titration/v8/data/cleared_colorspaces_masked_segmented_12122024_newdataset.xlsx'\n",
        "df = pd.read_excel(data_path)\n",
        "\n",
        "# Select only numerical columns for analysis\n",
        "columns_to_analyze = ['Mean_R', 'Mean_G', 'Mean_B', 'Mean_H', 'Mean_S', 'Mean_V', 'Mean_L', 'Mean_A', 'Mean_B_LAB']\n",
        "numeric_df = df[columns_to_analyze]\n",
        "\n",
        "# 1. RGB, HSV, LAB Histograms and Correlation Matrix\n",
        "plt.figure(figsize=(20, 15), dpi=300)  # High-quality output with increased DPI\n",
        "\n",
        "# RGB Histograms\n",
        "plt.subplot(5, 3, 1)\n",
        "plt.hist(df['Mean_R'], bins=30, color='red', alpha=0.7)\n",
        "plt.title('Mean R Distribution', fontsize=12)\n",
        "plt.xlabel('[O$_2$]tot', fontsize=12)\n",
        "plt.ylabel('Frequency', fontsize=12)\n",
        "\n",
        "plt.subplot(5, 3, 2)\n",
        "plt.hist(df['Mean_G'], bins=30, color='green', alpha=0.7)\n",
        "plt.title('Mean G Distribution', fontsize=12)\n",
        "plt.xlabel('[O$_2$]tot', fontsize=12)\n",
        "plt.ylabel('Frequency', fontsize=12)\n",
        "\n",
        "plt.subplot(5, 3, 3)\n",
        "plt.hist(df['Mean_B'], bins=30, color='blue', alpha=0.7)\n",
        "plt.title('Mean B Distribution', fontsize=12)\n",
        "plt.xlabel('[O$_2$]tot', fontsize=12)\n",
        "plt.ylabel('Frequency', fontsize=12)\n",
        "\n",
        "# HSV Histograms\n",
        "plt.subplot(5, 3, 4)\n",
        "plt.hist(df['Mean_H'], bins=30, color='orange', alpha=0.7)\n",
        "plt.title('Mean H Distribution', fontsize=12)\n",
        "plt.xlabel('[O$_2$]tot', fontsize=12)\n",
        "plt.ylabel('Frequency', fontsize=12)\n",
        "\n",
        "plt.subplot(5, 3, 5)\n",
        "plt.hist(df['Mean_S'], bins=30, color='green', alpha=0.7)\n",
        "plt.title('Mean S Distribution', fontsize=12)\n",
        "plt.xlabel('[O$_2$]tot', fontsize=12)\n",
        "plt.ylabel('Frequency', fontsize=12)\n",
        "\n",
        "plt.subplot(5, 3, 6)\n",
        "plt.hist(df['Mean_V'], bins=30, color='yellow', alpha=0.7)\n",
        "plt.title('Mean V Distribution', fontsize=12)\n",
        "plt.xlabel('[O$_2$]tot', fontsize=12)\n",
        "plt.ylabel('Frequency', fontsize=12)\n",
        "\n",
        "# LAB Histograms\n",
        "plt.subplot(5, 3, 7)\n",
        "plt.hist(df['Mean_L'], bins=30, color='gray', alpha=0.7)\n",
        "plt.title('Mean L Distribution', fontsize=12)\n",
        "plt.xlabel('[O$_2$]tot', fontsize=12)\n",
        "plt.ylabel('Frequency', fontsize=12)\n",
        "\n",
        "plt.subplot(5, 3, 8)\n",
        "plt.hist(df['Mean_A'], bins=30, color='purple', alpha=0.7)\n",
        "plt.title('Mean A Distribution', fontsize=12)\n",
        "plt.xlabel('[O$_2$]tot', fontsize=12)\n",
        "plt.ylabel('Frequency', fontsize=12)\n",
        "\n",
        "plt.subplot(5, 3, 9)\n",
        "plt.hist(df['Mean_B_LAB'], bins=30, color='blue', alpha=0.7)\n",
        "plt.title('Mean B_LAB Distribution', fontsize=12)\n",
        "plt.xlabel('[O$_2$]tot', fontsize=12)\n",
        "plt.ylabel('Frequency', fontsize=12)\n",
        "\n",
        "# Correlation Matrix\n",
        "plt.figure(figsize=(7, 7), dpi=300)  # High-quality output with increased DPI\n",
        "corr = numeric_df.corr()\n",
        "sns.heatmap(corr, annot=True, cmap='coolwarm', cbar=True, annot_kws={\"size\": 12})\n",
        "plt.title('Correlation Matrix', fontsize=12)\n",
        "plt.tight_layout()  # Optimize layout for high-quality output\n",
        "plt.show()\n",
        "\n",
        "# 2. Scatter Matrix (Pairplot) - All Parameter Combinations\n",
        "sns.pairplot(numeric_df, diag_kind='hist', corner=True, plot_kws={'alpha': 0.6})\n",
        "plt.suptitle('Scatter Matrix: All Parameter Combinations', fontsize=12, y=1.02)\n",
        "plt.tight_layout()  # Optimize layout for high-quality output\n",
        "plt.savefig('scatter_matrix.png', dpi=300, bbox_inches='tight')  # Save with high DPI\n",
        "plt.show()\n",
        "\n",
        "# 3. Boxplot - Distribution of Each Parameter Separately\n",
        "plt.figure(figsize=(10, 5), dpi=300)  # High-quality output with increased DPI\n",
        "sns.boxplot(data=numeric_df, orient='h', palette='Set2')\n",
        "plt.xlabel('Values of Color Spaces', fontsize=12)\n",
        "plt.ylabel('Color Spaces', fontsize=12)\n",
        "plt.tight_layout()  # Optimize layout for high-quality output\n",
        "plt.savefig('boxplot.png', dpi=300, bbox_inches='tight')  # Save with high DPI\n",
        "plt.show()\n",
        "\n",
        "# *** For details, contact the repository owner (Mirkan Emir Sancak, mrkn.sancak@gmail.com)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Wv0WSURvkKFZ",
        "outputId": "687d23cc-bf1e-44b2-a2c4-d48eba2dd84d"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# Load the dataset\n",
        "file_path = '/content/drive/MyDrive/visual titration/v8/data/cleared_colorspaces_masked_segmented_12122024_newdataset.xlsx'\n",
        "df = pd.read_excel(file_path)\n",
        "\n",
        "# Independent variable: Change this to the appropriate concentration column name\n",
        "X_column = '***'  # Replace with the correct column name representing concentration\n",
        "\n",
        "# Dependent variables (color space values) and standard deviations\n",
        "mean_columns = ['Mean_R', 'Mean_G', 'Mean_B', 'Mean_H', 'Mean_S', 'Mean_V', 'Mean_L', 'Mean_A', 'Mean_B_LAB']\n",
        "std_columns = ['Std_R', 'Std_G', 'Std_B', 'Std_H', 'Std_S', 'Std_V', 'Std_L', 'Std_A', 'Std_B_LAB']\n",
        "\n",
        "# Perform analysis for each mean column\n",
        "for mean_col, std_col in zip(mean_columns, std_columns):\n",
        "    # Remove rows with NaN values\n",
        "    valid_rows = df[[X_column, mean_col, std_col]].dropna()\n",
        "\n",
        "    # Independent and dependent variables\n",
        "    valid_X = valid_rows[X_column].values.reshape(-1, 1)\n",
        "    valid_y = valid_rows[mean_col].values.reshape(-1, 1)\n",
        "\n",
        "    if valid_y.size == 0 or valid_X.size == 0:\n",
        "        print(f\"Skipped {mean_col} due to insufficient data.\")\n",
        "        continue\n",
        "\n",
        "    # Linear regression model\n",
        "    linear_model = LinearRegression()\n",
        "    linear_model.fit(valid_X, valid_y)\n",
        "    linear_y_pred = linear_model.predict(valid_X)\n",
        "    linear_r2 = r2_score(valid_y, linear_y_pred)\n",
        "    equation = f\"y = {linear_model.coef_[0][0]:.2f}x + {linear_model.intercept_[0]:.2f}\"\n",
        "\n",
        "    # Plot results\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.errorbar(valid_rows[X_column], valid_rows[mean_col], yerr=valid_rows[std_col], fmt='o', label='Data Points', alpha=0.7)\n",
        "    plt.plot(valid_rows[X_column], linear_y_pred, color='red', label=f'Linear Fit (R²={linear_r2:.2f})', linestyle='--')\n",
        "    plt.xlabel(X_column)\n",
        "    plt.ylabel(f'{mean_col} (with {std_col} as Error Bars)')\n",
        "    plt.title(f'{X_column} vs {mean_col} with Linear Fit Line\\n{equation}')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "print(\"Analysis completed.\")\n",
        "\n",
        "# *** For details, contact the repository owner (Mirkan Emir Sancak, mrkn.sancak@gmail.com)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "IwUhI2NBJAE5",
        "outputId": "7af1d272-63ac-4469-fdaf-43b255687599"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# Load the dataset\n",
        "file_path = '/content/drive/MyDrive/visual titration/v8/data/cleared_colorspaces_masked_segmented_12122024_newdataset.xlsx'\n",
        "df = pd.read_excel(file_path)\n",
        "\n",
        "# Define the independent variable (concentration column)\n",
        "X_column = '***'  # Replace with the correct column name representing concentration\n",
        "\n",
        "# Dependent variable groups (color spaces)\n",
        "rgb_channels = ['Mean_R', 'Mean_G', 'Mean_B']\n",
        "hsv_channels = ['Mean_H', 'Mean_S', 'Mean_V']\n",
        "lab_channels = ['Mean_L', 'Mean_A', 'Mean_B_LAB']\n",
        "std_channels = ['Std_R', 'Std_G', 'Std_B', 'Std_H', 'Std_S', 'Std_V', 'Std_L', 'Std_A', 'Std_B_LAB']\n",
        "\n",
        "# Compute and visualize the correlation matrix\n",
        "correlation_matrix = df[[X_column] + rgb_channels + hsv_channels + lab_channels].corr()\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=0.5)\n",
        "plt.title(\"Correlation Matrix: Colorimetric Features & Ozone Concentration\")\n",
        "plt.show()\n",
        "\n",
        "# Function to process color space groups\n",
        "def plot_color_space_regression(color_channels, std_channels, title):\n",
        "    plt.figure(figsize=(12, 8))\n",
        "\n",
        "    for mean_col in color_channels:\n",
        "        std_col = std_channels[color_channels.index(mean_col)]\n",
        "\n",
        "        # Filter valid (non-NaN) rows\n",
        "        valid_rows = df[[X_column, mean_col, std_col]].dropna()\n",
        "        if valid_rows.empty:\n",
        "            print(f\"Skipped {mean_col} due to insufficient data.\")\n",
        "            continue\n",
        "\n",
        "        # Define independent and dependent variables\n",
        "        valid_X = valid_rows[X_column].values.reshape(-1, 1)\n",
        "        valid_y = valid_rows[mean_col].values.reshape(-1, 1)\n",
        "\n",
        "        # Create and train the linear regression model\n",
        "        linear_model = LinearRegression()\n",
        "        linear_model.fit(valid_X, valid_y)\n",
        "        linear_y_pred = linear_model.predict(valid_X)\n",
        "        linear_r2 = r2_score(valid_y, linear_y_pred)\n",
        "        equation = f\"{mean_col}: y = {linear_model.coef_[0][0]:.3f}x + {linear_model.intercept_[0]:.3f}\"\n",
        "\n",
        "        # Plot results\n",
        "        plt.errorbar(valid_rows[X_column], valid_rows[mean_col], yerr=valid_rows[std_col], fmt='o', label=f'{mean_col}', alpha=0.7)\n",
        "        plt.plot(valid_rows[X_column], linear_y_pred, linestyle='--', label=equation)\n",
        "\n",
        "    plt.xlabel(X_column)\n",
        "    plt.ylabel(\"Color Intensity\")\n",
        "    plt.title(title)\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Plot separate graphs for RGB, HSV, and LAB color spaces\n",
        "plot_color_space_regression(rgb_channels, std_channels[:3], \"RGB Color Space vs Ozone Concentration\")\n",
        "plot_color_space_regression(hsv_channels, std_channels[3:6], \"HSV Color Space vs Ozone Concentration\")\n",
        "plot_color_space_regression(lab_channels, std_channels[6:], \"LAB Color Space vs Ozone Concentration\")\n",
        "\n",
        "print(\"Analysis completed.\")\n",
        "\n",
        "# *** For details, contact the repository owner (Mirkan Emir Sancak, mrkn.sancak@gmail.com)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Q6frEOihcTIo",
        "outputId": "5eeaf3fc-1b2b-4fae-fa0a-eb65f977ef83"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# Load the dataset\n",
        "file_path = '/content/drive/MyDrive/visual titration/v8/data/cleared_colorspaces_masked_segmented_12122024_newdataset.xlsx'\n",
        "df = pd.read_excel(file_path)\n",
        "\n",
        "# Define the independent variable (concentration column)\n",
        "X_column = '***'  # Replace with the correct column name representing concentration\n",
        "\n",
        "# Dependent variable groups (color spaces)\n",
        "rgb_channels = ['Mean_R', 'Mean_G', 'Mean_B']\n",
        "hsv_channels = ['Mean_H', 'Mean_S', 'Mean_V']\n",
        "lab_channels = ['Mean_L', 'Mean_A', 'Mean_B_LAB']\n",
        "std_channels = ['Std_R', 'Std_G', 'Std_B', 'Std_H', 'Std_S', 'Std_V', 'Std_L', 'Std_A', 'Std_B_LAB']\n",
        "\n",
        "# Compute and visualize the correlation matrix without a title\n",
        "# Create a temporary DataFrame for the correlation matrix with renamed column for visualization\n",
        "correlation_temp_df = df[[X_column] + rgb_channels + hsv_channels + lab_channels].copy()\n",
        "correlation_temp_df.rename(columns={X_column: r'[O$_{x}$]$_{tot}$'}, inplace=True)\n",
        "\n",
        "correlation_matrix = correlation_temp_df.corr()\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=0.5)\n",
        "plt.show()\n",
        "\n",
        "# Function to process color space groups (titles removed)\n",
        "def plot_color_space_regression(color_channels, std_channels):\n",
        "    plt.figure(figsize=(12, 8))\n",
        "\n",
        "    for mean_col in color_channels:\n",
        "        std_col = std_channels[color_channels.index(mean_col)]\n",
        "\n",
        "        # Filter valid (non-NaN) rows\n",
        "        valid_rows = df[[X_column, mean_col, std_col]].dropna()\n",
        "        if valid_rows.empty:\n",
        "            print(f\"Skipped {mean_col} due to insufficient data.\")\n",
        "            continue\n",
        "\n",
        "        # Define independent and dependent variables\n",
        "        valid_X = valid_rows[X_column].values.reshape(-1, 1)\n",
        "        valid_y = valid_rows[mean_col].values.reshape(-1, 1)\n",
        "\n",
        "        # Create and train the linear regression model\n",
        "        linear_model = LinearRegression()\n",
        "        linear_model.fit(valid_X, valid_y)\n",
        "        linear_y_pred = linear_model.predict(valid_X)\n",
        "        linear_r2 = r2_score(valid_y, linear_y_pred)\n",
        "        equation = f\"{mean_col}: y = {linear_model.coef_[0][0]:.3f}x + {linear_model.intercept_[0]:.3f}\"\n",
        "\n",
        "        # Plot results (title removed, label updated with LaTeX for subscript)\n",
        "        plt.errorbar(valid_rows[X_column], valid_rows[mean_col], yerr=valid_rows[std_col], fmt='o', label=f'{mean_col}', alpha=0.7)\n",
        "        plt.plot(valid_rows[X_column], linear_y_pred, linestyle='--', label=equation)\n",
        "\n",
        "    plt.xlabel(r'[O$_{x}$]$_{tot}$')\n",
        "    plt.ylabel(\"Color Density\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Plot separate graphs for RGB, HSV, and LAB color spaces (titles removed)\n",
        "plot_color_space_regression(rgb_channels, std_channels[:3])\n",
        "plot_color_space_regression(hsv_channels, std_channels[3:6])\n",
        "plot_color_space_regression(lab_channels, std_channels[6:])\n",
        "\n",
        "print(\"Analysis completed.\")\n",
        "\n",
        "# *** For details, contact the repository owner (Mirkan Emir Sancak, mrkn.sancak@gmail.com)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CItiWYl5uoA9"
      },
      "source": [
        "DATASET EVALUATION"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Aepxb5EXLxt"
      },
      "source": [
        "interpolation according to concentration only linearization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 713
        },
        "id": "c0-XoM9PRGnr",
        "outputId": "9502ebcf-933d-4d75-8189-59d21b6a9e4a"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from google.colab import drive\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# File path (Google Drive)\n",
        "file_path = \"/content/drive/MyDrive/visual titration/v8/data/cleared_colorspaces_masked_segmented_12122024_newdataset.xlsx\"\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_excel(file_path)\n",
        "\n",
        "# Independent variable (Image column) - kept unchanged\n",
        "X_column = \"Image\"\n",
        "\n",
        "# Dependent variables (Color values)\n",
        "mean_columns = [\"Mean_R\", \"Mean_G\", \"Mean_B\", \"Mean_H\", \"Mean_S\", \"Mean_V\", \"Mean_L\", \"Mean_A\", \"Mean_B_LAB\"]\n",
        "\n",
        "# Create a copy of the original data to retain structure\n",
        "interpolated_data = df.copy()\n",
        "\n",
        "# Perform interpolation\n",
        "interpolation_models = {}\n",
        "\n",
        "for mean_col in mean_columns:\n",
        "    # Remove missing values\n",
        "    valid_rows = df[[X_column, mean_col]].dropna()\n",
        "\n",
        "    if valid_rows.empty:\n",
        "        print(f\"Skipping {mean_col} due to insufficient data.\")\n",
        "        continue\n",
        "\n",
        "    valid_X = valid_rows[X_column].values.reshape(-1, 1)\n",
        "    valid_y = valid_rows[mean_col].values.reshape(-1, 1)\n",
        "\n",
        "    # Apply linear regression\n",
        "    linear_model = LinearRegression()\n",
        "    linear_model.fit(valid_X, valid_y)\n",
        "    linear_y_pred = linear_model.predict(valid_X)\n",
        "    linear_r2 = r2_score(valid_y, linear_y_pred)\n",
        "\n",
        "    if linear_r2 >= 0.80:\n",
        "        print(f\"{mean_col}: Linear Regression Used (R² = {linear_r2:.2f})\")\n",
        "        interpolated_values = linear_model.predict(df[X_column].values.reshape(-1, 1)).flatten()\n",
        "        interpolation_models[mean_col] = \"Linear\"\n",
        "    else:\n",
        "        # Apply polynomial regression (degree 2)\n",
        "        poly_model = make_pipeline(PolynomialFeatures(degree=2), LinearRegression())\n",
        "        poly_model.fit(valid_X, valid_y)\n",
        "        poly_y_pred = poly_model.predict(valid_X)\n",
        "        poly_r2 = r2_score(valid_y, poly_y_pred)\n",
        "\n",
        "        print(f\"{mean_col}: Polynomial Regression Used (R² = {poly_r2:.2f})\")\n",
        "        interpolated_values = poly_model.predict(df[X_column].values.reshape(-1, 1)).flatten()\n",
        "        interpolation_models[mean_col] = \"Polynomial\"\n",
        "\n",
        "    # Write interpolation results to the corresponding column\n",
        "    interpolated_data[mean_col] = interpolated_values\n",
        "\n",
        "# Save interpolated results\n",
        "output_path = \"/content/drive/MyDrive/visual titration/v8/data/interpolated_cleared_colorspaces_masked_segmented_12122024_newdataset.xlsx\"\n",
        "interpolated_data.to_excel(output_path, index=False)\n",
        "print(f\"Interpolation completed and saved: {output_path}\")\n",
        "\n",
        "# Display the interpolation methods used\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.barplot(x=list(interpolation_models.keys()), y=[1 if v==\"Linear\" else 2 for v in interpolation_models.values()])\n",
        "plt.xticks(rotation=45)\n",
        "plt.yticks([1, 2], [\"Linear Regression\", \"Polynomial Regression\"])\n",
        "plt.ylabel(\"Selected Interpolation Method\")\n",
        "plt.title(\"Interpolation Method Chosen for Each Feature\")\n",
        "plt.grid(axis=\"y\")\n",
        "plt.show()\n",
        "\n",
        "# *** For details, contact the repository owner (Mirkan Emir Sancak, mrkn.sancak@gmail.com)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ERKS0yc97e4Y",
        "outputId": "0022b5f2-ca2d-46fa-dc63-8852391f7520"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the dataset\n",
        "data_path = '/content/drive/MyDrive/visual titration/v8/data/interpolated_cleared_colorspaces_masked_segmented_12122024_newdataset.xlsx'\n",
        "df = pd.read_excel(data_path)\n",
        "\n",
        "# Select only numerical columns (for analysis)\n",
        "columns_to_analyze = ['Mean_R', 'Mean_G', 'Mean_B', 'Mean_H', 'Mean_S', 'Mean_V', 'Mean_L', 'Mean_A', 'Mean_B_LAB']\n",
        "numeric_df = df[columns_to_analyze]\n",
        "\n",
        "# 1. RGB, HSV, LAB Histograms and Correlation Matrix\n",
        "plt.figure(figsize=(20, 15))\n",
        "\n",
        "# RGB Histograms\n",
        "plt.subplot(5, 3, 1)\n",
        "plt.hist(df['Mean_R'], bins=30, color='red', alpha=0.7)\n",
        "plt.title('Mean R Distribution')\n",
        "\n",
        "plt.subplot(5, 3, 2)\n",
        "plt.hist(df['Mean_G'], bins=30, color='green', alpha=0.7)\n",
        "plt.title('Mean G Distribution')\n",
        "\n",
        "plt.subplot(5, 3, 3)\n",
        "plt.hist(df['Mean_B'], bins=30, color='blue', alpha=0.7)\n",
        "plt.title('Mean B Distribution')\n",
        "\n",
        "# HSV Histograms\n",
        "plt.subplot(5, 3, 4)\n",
        "plt.hist(df['Mean_H'], bins=30, color='orange', alpha=0.7)\n",
        "plt.title('Mean H Distribution')\n",
        "\n",
        "plt.subplot(5, 3, 5)\n",
        "plt.hist(df['Mean_S'], bins=30, color='green', alpha=0.7)\n",
        "plt.title('Mean S Distribution')\n",
        "\n",
        "plt.subplot(5, 3, 6)\n",
        "plt.hist(df['Mean_V'], bins=30, color='yellow', alpha=0.7)\n",
        "plt.title('Mean V Distribution')\n",
        "\n",
        "# LAB Histograms\n",
        "plt.subplot(5, 3, 7)\n",
        "plt.hist(df['Mean_L'], bins=30, color='gray', alpha=0.7)\n",
        "plt.title('Mean L Distribution')\n",
        "\n",
        "plt.subplot(5, 3, 8)\n",
        "plt.hist(df['Mean_A'], bins=30, color='purple', alpha=0.7)\n",
        "plt.title('Mean A Distribution')\n",
        "\n",
        "plt.subplot(5, 3, 9)\n",
        "plt.hist(df['Mean_B_LAB'], bins=30, color='blue', alpha=0.7)\n",
        "plt.title('Mean B_LAB Distribution')\n",
        "\n",
        "# Correlation Matrix\n",
        "plt.figure(figsize=(12, 10))  # Increased size for better visualization\n",
        "corr = numeric_df.corr()\n",
        "sns.heatmap(corr, annot=True, cmap='coolwarm', cbar=True)\n",
        "plt.title('Correlation Matrix')\n",
        "plt.show()\n",
        "\n",
        "# 2. Scatter Matrix (Pairplot) - All Combinations\n",
        "sns.pairplot(numeric_df, diag_kind='hist', corner=True, plot_kws={'alpha': 0.6})\n",
        "plt.suptitle('Scatter Matrix: All Parameter Combinations', y=1.02)\n",
        "plt.show()\n",
        "\n",
        "# 3. Boxplot - Display the Distribution of Each Parameter Separately\n",
        "plt.figure(figsize=(16, 8))\n",
        "sns.boxplot(data=numeric_df, orient='h', palette='Set2')\n",
        "plt.title('Boxplot: Distribution of All Parameters')\n",
        "plt.xlabel('Values')\n",
        "plt.show()\n",
        "\n",
        "# *** For details, contact the repository owner (Mirkan Emir Sancak, mrkn.sancak@gmail.com)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "I6hpfeGtzc8C",
        "outputId": "b5352f2b-46af-4f6f-c0b9-cbe95b52bd5d"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# Load the dataset\n",
        "file_path = '/content/drive/MyDrive/visual titration/v8/data/interpolated_cleared_colorspaces_masked_segmented_12122024_newdataset.xlsx'\n",
        "df = pd.read_excel(file_path)\n",
        "\n",
        "# Use concentration data as the independent variable\n",
        "X_column = '***'  # Replace with the correct column name representing concentration\n",
        "\n",
        "# Dependent variables (color values)\n",
        "mean_columns = ['Mean_R', 'Mean_G', 'Mean_B', 'Mean_H', 'Mean_S', 'Mean_V', 'Mean_L', 'Mean_A', 'Mean_B_LAB']\n",
        "\n",
        "# Perform analysis for each mean column\n",
        "for mean_col in mean_columns:\n",
        "    # Remove rows with NaN values\n",
        "    valid_rows = df[[X_column, mean_col]].dropna()\n",
        "\n",
        "    # Independent and dependent variables\n",
        "    valid_X = valid_rows[X_column].values.reshape(-1, 1)\n",
        "    valid_y = valid_rows[mean_col].values.reshape(-1, 1)\n",
        "\n",
        "    if valid_y.size == 0 or valid_X.size == 0:\n",
        "        print(f\"Skipped {mean_col} due to insufficient data.\")\n",
        "        continue\n",
        "\n",
        "    # Linear regression model\n",
        "    linear_model = LinearRegression()\n",
        "    linear_model.fit(valid_X, valid_y)\n",
        "    linear_y_pred = linear_model.predict(valid_X)\n",
        "    linear_r2 = r2_score(valid_y, linear_y_pred)\n",
        "    equation = f\"y = {linear_model.coef_[0][0]:.2f}x + {linear_model.intercept_[0]:.2f}\"\n",
        "\n",
        "    # Plot results\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.scatter(valid_rows[X_column], valid_rows[mean_col], label='Data Points', alpha=0.7)\n",
        "    plt.plot(valid_rows[X_column], linear_y_pred, color='red', label=f'Linear Fit (R²={linear_r2:.2f})', linestyle='--')\n",
        "    plt.xlabel(X_column)\n",
        "    plt.ylabel(mean_col)\n",
        "    plt.title(f'{X_column} vs {mean_col} with Linear Fit Line\\n{equation}')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "print(\"Analysis completed.\")\n",
        "\n",
        "# *** For details, contact the repository owner (Mirkan Emir Sancak, mrkn.sancak@gmail.com)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "SlnZ17920zSp",
        "outputId": "f2e5a2e9-ebd8-49c3-dd6f-dd2e006918a4"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# Load the dataset\n",
        "file_path = '/content/drive/MyDrive/visual titration/v8/data/interpolated_cleared_colorspaces_masked_segmented_12122024_newdataset.xlsx'\n",
        "df = pd.read_excel(file_path)\n",
        "\n",
        "# Define the independent variable (concentration column)\n",
        "X_column = '***'  # Replace with the correct column name representing concentration\n",
        "\n",
        "# Dependent variable groups (color spaces)\n",
        "rgb_channels = ['Mean_R', 'Mean_G', 'Mean_B']\n",
        "hsv_channels = ['Mean_H', 'Mean_S', 'Mean_V']\n",
        "lab_channels = ['Mean_L', 'Mean_A', 'Mean_B_LAB']\n",
        "\n",
        "# Compute and visualize the correlation matrix\n",
        "correlation_matrix = df[[X_column] + rgb_channels + hsv_channels + lab_channels].corr()\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=0.5)\n",
        "plt.title(\"Correlation Matrix: Colorimetric Features & Ozone Concentration\")\n",
        "plt.show()\n",
        "\n",
        "# Function to process color space groups\n",
        "def plot_color_space_regression(color_channels, title):\n",
        "    plt.figure(figsize=(12, 8))\n",
        "\n",
        "    for mean_col in color_channels:\n",
        "        # Filter valid (non-NaN) rows\n",
        "        valid_rows = df[[X_column, mean_col]].dropna()\n",
        "        if valid_rows.empty:\n",
        "            print(f\"Skipped {mean_col} due to insufficient data.\")\n",
        "            continue\n",
        "\n",
        "        # Define independent and dependent variables\n",
        "        valid_X = valid_rows[X_column].values.reshape(-1, 1)\n",
        "        valid_y = valid_rows[mean_col].values.reshape(-1, 1)\n",
        "\n",
        "        # Create and train the linear regression model\n",
        "        linear_model = LinearRegression()\n",
        "        linear_model.fit(valid_X, valid_y)\n",
        "        linear_y_pred = linear_model.predict(valid_X)\n",
        "        linear_r2 = r2_score(valid_y, linear_y_pred)\n",
        "        equation = f\"{mean_col}: y = {linear_model.coef_[0][0]:.3f}x + {linear_model.intercept_[0]:.3f}\"\n",
        "\n",
        "        # Plot results\n",
        "        plt.scatter(valid_rows[X_column], valid_rows[mean_col], label=f'{mean_col}', alpha=0.7)\n",
        "        plt.plot(valid_rows[X_column], linear_y_pred, linestyle='--', label=equation)\n",
        "\n",
        "    plt.xlabel(X_column)\n",
        "    plt.ylabel(\"Color Intensity\")\n",
        "    plt.title(title)\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Plot separate graphs for RGB, HSV, and LAB color spaces\n",
        "plot_color_space_regression(rgb_channels, \"RGB Color Space vs Ozone Concentration\")\n",
        "plot_color_space_regression(hsv_channels, \"HSV Color Space vs Ozone Concentration\")\n",
        "plot_color_space_regression(lab_channels, \"LAB Color Space vs Ozone Concentration\")\n",
        "\n",
        "print(\"Analysis completed.\")\n",
        "\n",
        "# *** For details, contact the repository owner (Mirkan Emir Sancak, mrkn.sancak@gmail.com)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ic1HKJ3Xut8S"
      },
      "source": [
        "MACHINE LEARNING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "vAww55J86rHm",
        "outputId": "4a909f65-9249-4e3a-ccdc-c78606c53b74"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.feature_selection import SelectKBest, f_regression\n",
        "\n",
        "# Load the Excel dataset\n",
        "df = pd.read_excel('/content/drive/MyDrive/visual titration/v8/data/interpolated_cleared_colorspaces_masked_segmented_12122024_newdataset.xlsx')\n",
        "\n",
        "# Function to extract concentration information\n",
        "def extract_concentration(image_name):\n",
        "    match = re.search(r'(\\d+)', str(image_name))\n",
        "    return int(match.group(1)) if match else None\n",
        "\n",
        "# Add extracted concentration as a column\n",
        "df['Image'] = df['Image'].apply(extract_concentration)\n",
        "df.sort_values('Image', inplace=True)\n",
        "\n",
        "# Define feature columns (excluding standard deviation values)\n",
        "mean_columns = [col for col in df.columns if 'Mean_' in col and 'Std' not in col]\n",
        "X = df[mean_columns].values  # Independent variables\n",
        "y = df['Image'].values  # Target variable\n",
        "\n",
        "# Display dataset statistics\n",
        "print(\"\\n### Dataset Statistics ###\")\n",
        "print(f\"Total Data Points: {len(df)}\")\n",
        "print(f\"Number of Features: {len(mean_columns)}\")\n",
        "print(\"Feature Names:\", mean_columns)\n",
        "\n",
        "# Display target variable (y) statistics\n",
        "print(\"\\nTarget Variable (Concentration) Statistics:\")\n",
        "print(f\"Mean: {np.mean(y):.2f}\")\n",
        "print(f\"Standard Deviation: {np.std(y):.2f}\")\n",
        "print(f\"Minimum Value: {np.min(y)}\")\n",
        "print(f\"Maximum Value: {np.max(y)}\")\n",
        "print(f\"Number of NaN Values in Target: {np.isnan(y).sum()}\")\n",
        "\n",
        "# Check for missing values in features\n",
        "nan_counts = pd.DataFrame(X, columns=mean_columns).isna().sum()\n",
        "print(\"\\nNumber of Missing Values in Features:\")\n",
        "print(nan_counts)\n",
        "\n",
        "# Split dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize features (necessary for Neural Networks)\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Define models\n",
        "models = {\n",
        "    'Linear Regression': LinearRegression(),\n",
        "    'Ridge Regression': Ridge(),\n",
        "    'Lasso Regression': Lasso(),\n",
        "    'Random Forest': RandomForestRegressor(n_estimators=100, random_state=42),\n",
        "    'Neural Network': MLPRegressor(hidden_layer_sizes=(100,), max_iter=1000, random_state=42)\n",
        "}\n",
        "\n",
        "# Create a DataFrame to store model performance\n",
        "results = pd.DataFrame(columns=['Model', 'R2', 'MSE', 'MAE'])\n",
        "\n",
        "# Train and evaluate models\n",
        "for model_name, model in models.items():\n",
        "    if model_name == 'Neural Network':\n",
        "        model.fit(X_train_scaled, y_train)\n",
        "        y_pred = model.predict(X_test_scaled)\n",
        "    else:\n",
        "        model.fit(X_train, y_train)\n",
        "        y_pred = model.predict(X_test)\n",
        "\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    mae = mean_absolute_error(y_test, y_pred)\n",
        "\n",
        "    new_row = pd.DataFrame({'Model': [model_name], 'R2': [r2], 'MSE': [mse], 'MAE': [mae]})\n",
        "    results = pd.concat([results, new_row], ignore_index=True)\n",
        "\n",
        "    # Scatter plot of predictions vs true values\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.scatter(y_test, y_pred, alpha=0.7, label='Predicted')\n",
        "    plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], color='red', linestyle='--', label='Best Fit')\n",
        "    plt.xlabel('True Concentration')\n",
        "    plt.ylabel('Predicted Concentration')\n",
        "    plt.title(f'{model_name} - Predicted vs True')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Display model performance comparison\n",
        "print(\"\\nModel Performance Comparisons:\")\n",
        "print(results)\n",
        "\n",
        "# Visualize model performance\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x='Model', y='R2', data=results)\n",
        "plt.title('Comparison of Model Performance (R²)')\n",
        "plt.ylabel('R² Score')\n",
        "plt.xlabel('Model')\n",
        "plt.grid(True, axis='y')\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Target variable distribution\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.histplot(y, kde=True, bins=20)\n",
        "plt.title('Target Variable Distribution (Image)')\n",
        "plt.xlabel('Image')\n",
        "plt.ylabel('Frequency')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# Scatter plots of features vs target variable\n",
        "for col in mean_columns:\n",
        "    plt.figure(figsize=(6, 4))\n",
        "    plt.scatter(df[col], df['Image'], alpha=0.5)\n",
        "    plt.xlabel(col)\n",
        "    plt.ylabel('Image')\n",
        "    plt.title(f'{col} vs Image')\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "# Correlation matrix\n",
        "correlation_matrix = df[mean_columns + ['Image']].corr()\n",
        "plt.figure(figsize=(12, 10))\n",
        "sns.heatmap(correlation_matrix, annot=True, fmt='.2f', cmap='coolwarm')\n",
        "plt.title('Correlation Matrix')\n",
        "plt.show()\n",
        "\n",
        "# Compare training and test performance\n",
        "for model_name, model in models.items():\n",
        "    if model_name == 'Neural Network':\n",
        "        y_train_pred = model.predict(X_train_scaled)\n",
        "        y_test_pred = model.predict(X_test_scaled)\n",
        "    else:\n",
        "        y_train_pred = model.predict(X_train)\n",
        "        y_test_pred = model.predict(X_test)\n",
        "\n",
        "    # Training and test R² scores\n",
        "    train_r2 = r2_score(y_train, y_train_pred)\n",
        "    test_r2 = r2_score(y_test, y_test_pred)\n",
        "\n",
        "    print(f\"{model_name} -> Training R²: {train_r2:.3f}, Test R²: {test_r2:.3f}\")\n",
        "\n",
        "# Feature Selection\n",
        "selector = SelectKBest(score_func=f_regression, k=5)\n",
        "X_new = selector.fit_transform(X, y)\n",
        "selected_features = np.array(mean_columns)[selector.get_support()]\n",
        "print(\"\\nSelected Features:\", selected_features)\n",
        "\n",
        "# Retrieve F-scores and p-values\n",
        "f_scores = selector.scores_\n",
        "p_values = selector.pvalues_\n",
        "feature_scores = pd.DataFrame({\n",
        "    'Feature': mean_columns,\n",
        "    'F-Score': f_scores,\n",
        "    'P-Value': p_values\n",
        "})\n",
        "print(\"\\nF-Scores and P-Values for All Features:\")\n",
        "print(feature_scores.sort_values(by='F-Score', ascending=False))\n",
        "\n",
        "# Correlation matrix for selected features\n",
        "selected_df = df[list(selected_features) + ['Image']]\n",
        "correlation_matrix_selected = selected_df.corr()\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(correlation_matrix_selected, annot=True, fmt='.2f', cmap='coolwarm')\n",
        "plt.title('Correlation Matrix of Selected Features and Target Variable')\n",
        "plt.show()\n",
        "\n",
        "# Final performance summary\n",
        "final_results = []\n",
        "\n",
        "for model_name, model in models.items():\n",
        "    if model_name == 'Neural Network':\n",
        "        y_train_pred = model.predict(X_train_scaled)\n",
        "        y_test_pred = model.predict(X_test_scaled)\n",
        "    else:\n",
        "        y_train_pred = model.predict(X_train)\n",
        "        y_test_pred = model.predict(X_test)\n",
        "\n",
        "    # Compute performance metrics\n",
        "    train_r2 = r2_score(y_train, y_train_pred)\n",
        "    test_r2 = r2_score(y_test, y_test_pred)\n",
        "    test_mse = mean_squared_error(y_test, y_test_pred)\n",
        "    test_mae = mean_absolute_error(y_test, y_test_pred)\n",
        "\n",
        "    # Append results\n",
        "    final_results.append({\n",
        "        'Model': model_name,\n",
        "        'Training R²': train_r2,\n",
        "        'Test R²': test_r2,\n",
        "        'Test MSE': test_mse,\n",
        "        'Test MAE': test_mae\n",
        "    })\n",
        "\n",
        "# Convert results to DataFrame\n",
        "final_results_df = pd.DataFrame(final_results)\n",
        "\n",
        "# Print final performance summary\n",
        "print(\"\\nFinal Model Performance Summary:\")\n",
        "print(final_results_df)\n",
        "\n",
        "# *** For details, contact the repository owner (Mirkan Emir Sancak, mrkn.sancak@gmail.com)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "292ce27bce6747f3aba6486fee6849e7",
            "d1460f7936c54ed5b0d21e64bca64dc4",
            "a815c1c0a50848a79fa887ec2e297c37",
            "a810e5599d6d42aaa6f89bc9d3d2fdee",
            "97ecd6485ad0436392225ba946276bac",
            "f8d414dc50724a8ab7d7c0955ee77fe9",
            "bb02e3c86e3b49278170f32ffbaf1510",
            "e5f5c56b1a0640dc93685a4786c888ff",
            "45c2cb89728645a6b8ab85f6566d3e76",
            "ae828bb69fa541b48ef6132a428061da",
            "70b9d5b797c0461c9e75c6e5d0f5acb3",
            "cdd464ceba884e479da5532190e3dcfe",
            "6898af0fcc4a4cef9c5692e516d6bef9",
            "98d5fbe5431f47b2af345ef0a84c7b9f",
            "ac33b4be5a8b4e86bfd9379e06566ae3",
            "d130547d9eb94159bfaead2d2dcb3754",
            "e0b8e9e5f64d47cd865ae633fced9ef1",
            "94f6af18d5f848d7b6e5071730894ff2",
            "3d330cc75e544dc8b5d2c8804c561982",
            "e1d20eb5858146a2abf08fec113aab2d",
            "229ad7e775874317aa31ea04b56c8d1c",
            "b9cd0ba5f1b54608bd5a4d19b989d51f"
          ]
        },
        "id": "m4NFOCxrNMVv",
        "outputId": "ed1a08ec-4c0f-46e0-aa56-1aebfd73fde4"
      },
      "outputs": [],
      "source": [
        "import shap\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# List of labels for the plots\n",
        "labels = [\"a)\", \"b)\", \"c)\", \"d)\", \"e)\"]  # Extend this list if needed based on the number of models\n",
        "\n",
        "# Perform SHAP analysis for all models\n",
        "for idx, (model_name, model) in enumerate(models.items()):\n",
        "    print(f\"\\n--- SHAP Analysis: {model_name} ---\")\n",
        "\n",
        "    # Train the model\n",
        "    if model_name == 'Neural Network':\n",
        "        model.fit(X_train_scaled, y_train)\n",
        "        X_ref, X_plot = X_train_scaled, X_test_scaled\n",
        "    else:\n",
        "        model.fit(X_train, y_train)\n",
        "        X_ref, X_plot = X_train, X_test\n",
        "\n",
        "    # Select the appropriate SHAP explainer\n",
        "    if model_name in ['Neural Network', 'Random Forest']:\n",
        "        explainer = shap.KernelExplainer(model.predict, X_ref)\n",
        "    else:\n",
        "        explainer = shap.Explainer(model, X_ref)\n",
        "\n",
        "    # Compute SHAP values\n",
        "    shap_values = explainer.shap_values(X_plot)\n",
        "\n",
        "    # Create a new figure\n",
        "    plt.figure(figsize=(10, 6))\n",
        "\n",
        "    # Generate SHAP summary plot\n",
        "    shap.summary_plot(shap_values, X_plot, feature_names=mean_columns, show=False)\n",
        "\n",
        "    # Add a label to the plot\n",
        "    plt.text(0.4, 1.05, labels[idx], fontsize=16, fontweight='bold', transform=plt.gca().transAxes)\n",
        "\n",
        "    # Display the plot\n",
        "    plt.show()\n",
        "\n",
        "# *** For details, contact the repository owner (Mirkan Emir Sancak, mrkn.sancak@gmail.com)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "qsr9zTImRwmx",
        "outputId": "8605b12a-02b7-4291-b307-c8591e6148ce"
      },
      "outputs": [],
      "source": [
        "!pip install lime\n",
        "import lime\n",
        "import lime.lime_tabular\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Create a LIME explainer\n",
        "explainer = lime.lime_tabular.LimeTabularExplainer(\n",
        "    training_data=X_train_scaled,  # Using scaled data since features are standardized\n",
        "    feature_names=mean_columns,\n",
        "    class_names=['Concentration'],\n",
        "    mode='regression',\n",
        "    discretize_continuous=True,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Select a test sample to explain (using the first test data point as an example)\n",
        "test_sample_index = 0\n",
        "test_sample = X_test_scaled[test_sample_index].reshape(1, -1)\n",
        "\n",
        "# Label sequence for the plots\n",
        "labels = [\"a)\", \"b)\", \"c)\", \"d)\", \"e)\"]\n",
        "\n",
        "# Run LIME analysis for all models\n",
        "for i, (model_name, model) in enumerate(models.items()):\n",
        "    print(f\"\\n--- LIME Analysis: {model_name} ---\")\n",
        "\n",
        "    # Train the model (if already trained, this step can be commented out)\n",
        "    if model_name == 'Neural Network':\n",
        "        model.fit(X_train_scaled, y_train)\n",
        "    else:\n",
        "        model.fit(X_train, y_train)\n",
        "\n",
        "    # Define the model prediction function\n",
        "    def model_predict(data):\n",
        "        return model.predict(data).reshape(-1, 1)\n",
        "\n",
        "    # Generate LIME explanation\n",
        "    exp = explainer.explain_instance(\n",
        "        test_sample.flatten(),\n",
        "        model_predict,\n",
        "        num_features=5  # Show top 5 most important features\n",
        "    )\n",
        "\n",
        "    # Visualize the LIME result (adjusting colors for grayscale)\n",
        "    fig = exp.as_pyplot_figure()\n",
        "\n",
        "    # Set bars to grayscale with black edges\n",
        "    for bar in fig.axes[0].patches:\n",
        "        bar.set_facecolor('gray')  # Set all bars to gray\n",
        "        bar.set_edgecolor('black')  # Set edges to black\n",
        "\n",
        "    fig.tight_layout()\n",
        "    plt.title(f\"{labels[i]}\")  # Using letters instead of model names\n",
        "    plt.show()\n",
        "\n",
        "# *** For details, contact the repository owner (Mirkan Emir Sancak, mrkn.sancak@gmail.com)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qsIAD6m557Ef"
      },
      "source": [
        "MODEL VALIDATION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "YSCLFBDy6E10",
        "outputId": "1866faab-5f69-4864-c3f0-9393b6f88879"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
        "from sklearn.model_selection import train_test_split, learning_curve\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.feature_selection import SelectKBest, f_regression\n",
        "\n",
        "# Load the Excel file\n",
        "df = pd.read_excel('/content/drive/MyDrive/visual titration/v8/data/interpolated_cleared_colorspaces_masked_segmented_12122024_newdataset.xlsx')\n",
        "\n",
        "# Function to extract concentration information from image names\n",
        "def extract_concentration(image_name):\n",
        "    match = re.search(r'(\\d+)', str(image_name))\n",
        "    return int(match.group(1)) if match else None\n",
        "\n",
        "# Add extracted concentration data as a new column\n",
        "df['Image'] = df['Image'].apply(extract_concentration)\n",
        "df.sort_values('Image', inplace=True)\n",
        "\n",
        "# Identify feature columns (excluding standard deviation data)\n",
        "mean_columns = [col for col in df.columns if 'Mean_' in col and 'Std' not in col]\n",
        "\n",
        "# Feature selection using f_regression\n",
        "X_all = df[mean_columns].values  # All features\n",
        "y = df['Image'].values  # Target variable\n",
        "selector = SelectKBest(score_func=f_regression, k=5)\n",
        "X_new = selector.fit_transform(X_all, y)\n",
        "selected_features = np.array(mean_columns)[selector.get_support()]\n",
        "print(\"Selected Features:\", selected_features)\n",
        "\n",
        "# Create X with selected features\n",
        "X = df[selected_features].values  # Independent variables\n",
        "\n",
        "# Print dataset statistics\n",
        "print(\"\\n### Data Statistics ###\")\n",
        "print(f\"Total Number of Data Points: {len(df)}\")\n",
        "print(f\"Number of Independent Variables (Features): {len(selected_features)}\")\n",
        "print(\"Selected Feature Names:\", selected_features)\n",
        "\n",
        "# Target variable (y) statistics\n",
        "print(\"\\nTarget Variable (Concentration) Statistics:\")\n",
        "print(f\"Mean: {np.mean(y):.2f}\")\n",
        "print(f\"Standard Deviation: {np.std(y):.2f}\")\n",
        "print(f\"Minimum Value: {np.min(y)}\")\n",
        "print(f\"Maximum Value: {np.max(y)}\")\n",
        "print(f\"NaN Values in Target: {np.isnan(y).sum()}\")\n",
        "\n",
        "# Check for NaN values in independent variables\n",
        "nan_counts = pd.DataFrame(X, columns=selected_features).isna().sum()\n",
        "print(\"\\nNaN Values in Independent Variables:\")\n",
        "print(nan_counts)\n",
        "\n",
        "# Split data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Feature standardization (necessary for Neural Network)\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Define models\n",
        "models = {\n",
        "    'Linear Regression': LinearRegression(),\n",
        "    'Ridge Regression': Ridge(),\n",
        "    'Lasso Regression': Lasso(),\n",
        "    'Random Forest': RandomForestRegressor(n_estimators=100, random_state=42),\n",
        "    'Neural Network': MLPRegressor(hidden_layer_sizes=(100,), max_iter=1000, random_state=42)\n",
        "}\n",
        "\n",
        "# Create an empty DataFrame for results\n",
        "results = pd.DataFrame(columns=['Model', 'R2', 'MSE', 'MAE'])\n",
        "\n",
        "# Train and evaluate models\n",
        "for model_name, model in models.items():\n",
        "    if model_name == 'Neural Network':\n",
        "        model.fit(X_train_scaled, y_train)\n",
        "        y_pred = model.predict(X_test_scaled)\n",
        "    else:\n",
        "        model.fit(X_train, y_train)\n",
        "        y_pred = model.predict(X_test)\n",
        "\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    mae = mean_absolute_error(y_test, y_pred)\n",
        "\n",
        "    new_row = pd.DataFrame({'Model': [model_name], 'R2': [r2], 'MSE': [mse], 'MAE': [mae]})\n",
        "    results = pd.concat([results, new_row], ignore_index=True)\n",
        "\n",
        "    # Scatter plot of predicted vs. true values\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.scatter(y_test, y_pred, alpha=0.7, label='Predicted')\n",
        "    plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], color='red', linestyle='--', label='Best Fit')\n",
        "    plt.xlabel('True Concentration')\n",
        "    plt.ylabel('Predicted Concentration')\n",
        "    plt.title(f'{model_name} - Predicted vs True')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "print(\"\\nModel Performance Comparison:\")\n",
        "print(results)\n",
        "\n",
        "# Bar plot of R² scores\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x='Model', y='R2', data=results)\n",
        "plt.title('Comparison of Model Performance (R^2)')\n",
        "plt.ylabel('R^2 Score')\n",
        "plt.xlabel('Model')\n",
        "plt.grid(True, axis='y')\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Distribution of the target variable\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.histplot(y, kde=True, bins=20)\n",
        "plt.title('Distribution of Target Variable (Image)')\n",
        "plt.xlabel('Image')\n",
        "plt.ylabel('Frequency')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# Relationship between selected features and the target variable\n",
        "for col in selected_features:\n",
        "    plt.figure(figsize=(6, 4))\n",
        "    plt.scatter(df[col], df['Image'], alpha=0.5)\n",
        "    plt.xlabel(col)\n",
        "    plt.ylabel('Image')\n",
        "    plt.title(f'{col} vs Image')\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "# Correlation matrix\n",
        "correlation_matrix = df[list(selected_features) + ['Image']].corr()\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(correlation_matrix, annot=True, fmt='.2f', cmap='coolwarm')\n",
        "plt.title('Correlation Matrix (Selected Features)')\n",
        "plt.show()\n",
        "\n",
        "# Compare training and test performance\n",
        "for model_name, model in models.items():\n",
        "    if model_name == 'Neural Network':\n",
        "        y_train_pred = model.predict(X_train_scaled)\n",
        "        y_test_pred = model.predict(X_test_scaled)\n",
        "    else:\n",
        "        y_train_pred = model.predict(X_train)\n",
        "        y_test_pred = model.predict(X_test)\n",
        "\n",
        "    train_r2 = r2_score(y_train, y_train_pred)\n",
        "    test_r2 = r2_score(y_test, y_test_pred)\n",
        "\n",
        "    print(f\"{model_name} -> Training R2: {train_r2:.3f}, Test R2: {test_r2:.3f}\")\n",
        "\n",
        "# Function to plot learning curves\n",
        "def plot_learning_curve(estimator, X, y, title):\n",
        "    train_sizes, train_scores, test_scores = learning_curve(estimator, X, y, cv=5, scoring='r2',\n",
        "                                                            train_sizes=np.linspace(0.1, 1.0, 10))\n",
        "    train_mean = np.mean(train_scores, axis=1)\n",
        "    train_std = np.std(train_scores, axis=1)\n",
        "    test_mean = np.mean(test_scores, axis=1)\n",
        "    test_std = np.std(test_scores, axis=1)\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.plot(train_sizes, train_mean, 'o-', label='Training')\n",
        "    plt.plot(train_sizes, test_mean, 'o-', label='Validation')\n",
        "    plt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, alpha=0.2)\n",
        "    plt.fill_between(train_sizes, test_mean - test_std, test_mean + test_std, alpha=0.2)\n",
        "    plt.title(title)\n",
        "    plt.xlabel('Size of Training Dataset')\n",
        "    plt.ylabel('R^2 Score')\n",
        "    plt.legend()\n",
        "    plt.grid()\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Plot learning curves for all models\n",
        "for model_name, model in models.items():\n",
        "    if model_name == 'Neural Network':\n",
        "        plot_learning_curve(model, X_train_scaled, y_train, f'{model_name} - Learning Curve')\n",
        "    else:\n",
        "        plot_learning_curve(model, X_train, y_train, f'{model_name} - Learning Curve')\n",
        "\n",
        "# *** For details, contact the repository owner (Mirkan Emir Sancak, mrkn.sancak@gmail.com)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-4hZKqPC8eM7",
        "outputId": "6f2201aa-bfdb-484b-ae52-8b878f4724f9"
      },
      "outputs": [],
      "source": [
        "# Combine performance results of all models\n",
        "final_results = []\n",
        "\n",
        "for model_name, model in models.items():\n",
        "    if model_name == 'Neural Network':\n",
        "        y_train_pred = model.predict(X_train_scaled)\n",
        "        y_test_pred = model.predict(X_test_scaled)\n",
        "    else:\n",
        "        y_train_pred = model.predict(X_train)\n",
        "        y_test_pred = model.predict(X_test)\n",
        "\n",
        "    # Performance metrics\n",
        "    train_r2 = r2_score(y_train, y_train_pred)\n",
        "    test_r2 = r2_score(y_test, y_test_pred)\n",
        "    test_mse = mean_squared_error(y_test, y_test_pred)\n",
        "    test_mae = mean_absolute_error(y_test, y_test_pred)\n",
        "\n",
        "    # Append results\n",
        "    final_results.append({\n",
        "        'Model': model_name,\n",
        "        'Train R2': train_r2,\n",
        "        'Test R2': test_r2,\n",
        "        'Test MSE': test_mse,\n",
        "        'Test MAE': test_mae\n",
        "    })\n",
        "\n",
        "# Convert results to a DataFrame\n",
        "final_results_df = pd.DataFrame(final_results)\n",
        "\n",
        "# Print performance summary\n",
        "print(\"\\nModel Performance Summary:\")\n",
        "print(final_results_df)\n",
        "\n",
        "# *** For details, contact the repository owner (Mirkan Emir Sancak, mrkn.sancak@gmail.com)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 733
        },
        "id": "HslYS6V4Nog-",
        "outputId": "2afb4891-9350-4b05-967b-6c44adb45b12"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import gridspec\n",
        "\n",
        "# Load the uploaded image\n",
        "image_path = \"/content/drive/MyDrive/visual titration/v8/data/segmented_12122024_newdataset/12-1_crop_0.jpg\"\n",
        "image = cv2.imread(image_path)\n",
        "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convert to RGB for visualization\n",
        "\n",
        "# Step 1: HSV Thresholding (Isolating Target Region)\n",
        "hsv = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n",
        "lower_bound = np.array([0, 112, 26])  # Adjust based on target color range\n",
        "upper_bound = np.array([179, 255, 146])\n",
        "mask = cv2.inRange(hsv, lower_bound, upper_bound)\n",
        "\n",
        "# Step 2: Inpainting only on the background (non-ROI areas)\n",
        "mask_inv = cv2.bitwise_not(mask)\n",
        "background = cv2.inpaint(image, mask_inv, inpaintRadius=3, flags=cv2.INPAINT_TELEA)\n",
        "inpainted = cv2.bitwise_and(background, background, mask=mask)  # Keep only ROI\n",
        "\n",
        "# Step 3: CLAHE (Contrast Enhancement)\n",
        "lab = cv2.cvtColor(inpainted, cv2.COLOR_RGB2LAB)\n",
        "l, a, b = cv2.split(lab)\n",
        "\n",
        "clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8, 8))\n",
        "l_clahe = clahe.apply(l)\n",
        "\n",
        "lab_clahe = cv2.merge((l_clahe, a, b))\n",
        "enhanced = cv2.cvtColor(lab_clahe, cv2.COLOR_LAB2RGB)\n",
        "\n",
        "# Step 4: Final Processed Image (Optimized Output)\n",
        "final_output = enhanced  # This is the fully processed image\n",
        "\n",
        "# Visualization with custom layout: 3 images in first row, 2 centered in second\n",
        "fig = plt.figure(figsize=(15, 10))  # Adjusted size: wider for 3 images, shorter height\n",
        "\n",
        "# Define titles with only alphabetical labels\n",
        "labels = [\"a)\", \"b)\", \"c)\", \"d)\", \"e)\"]\n",
        "images = [image, cv2.bitwise_and(image, image, mask=mask), inpainted, enhanced, final_output]\n",
        "\n",
        "# Create a GridSpec layout: 2 rows, 6 columns (to allow precise centering)\n",
        "gs = gridspec.GridSpec(2, 6, height_ratios=[1, 1])\n",
        "\n",
        "# Row 1: 3 images (A, B, C) evenly spaced across 6 columns\n",
        "ax1 = plt.subplot(gs[0, 0:2])  # First row, spans columns 0-1 (left)\n",
        "ax1.imshow(images[0])\n",
        "ax1.set_title(labels[0], fontsize=18, pad=3)\n",
        "ax1.axis(\"off\")\n",
        "\n",
        "ax2 = plt.subplot(gs[0, 2:4])  # First row, spans columns 2-3 (middle)\n",
        "ax2.imshow(images[1])\n",
        "ax2.set_title(labels[1], fontsize=18, pad=3)\n",
        "ax2.axis(\"off\")\n",
        "\n",
        "ax3 = plt.subplot(gs[0, 4:6])  # First row, spans columns 4-5 (right)\n",
        "ax3.imshow(images[2])\n",
        "ax3.set_title(labels[2], fontsize=18, pad=3)\n",
        "ax3.axis(\"off\")\n",
        "\n",
        "# Row 2: 2 images (D and E), centered using columns 1-4\n",
        "ax4 = plt.subplot(gs[1, 1:3])  # Second row, spans columns 1-2 (left-center)\n",
        "ax4.imshow(images[3])\n",
        "ax4.set_title(labels[3], fontsize=18, pad=3)\n",
        "ax4.axis(\"off\")\n",
        "\n",
        "ax5 = plt.subplot(gs[1, 3:5])  # Second row, spans columns 3-4 (right-center)\n",
        "ax5.imshow(images[4])\n",
        "ax5.set_title(labels[4], fontsize=18, pad=3)\n",
        "ax5.axis(\"off\")\n",
        "\n",
        "# Adjust layout to minimize spacing\n",
        "plt.tight_layout(pad=1, h_pad=1, w_pad=1)  # Tighter padding to bring images closer\n",
        "plt.show()\n",
        "\n",
        "# *** For details, contact the repository owner (Mirkan Emir Sancak, mrkn.sancak@gmail.com)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "oc-zQRy7XYRy",
        "outputId": "4a907b4b-8266-45dd-839a-0ae9196af2a7"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "from matplotlib import gridspec\n",
        "\n",
        "# Define the path to a single image\n",
        "image_path = \"/content/drive/MyDrive/visual titration/v8/data/masked_segmented_12122024_newdataset/masked_12-1_crop_0.jpg\"\n",
        "\n",
        "# Load the image\n",
        "image = cv2.imread(image_path)\n",
        "\n",
        "# Skip if the image cannot be loaded\n",
        "if image is None:\n",
        "    print(f\"Error loading image: {image_path}\")\n",
        "    exit()\n",
        "\n",
        "# Path to the Excel file containing HSV ranges\n",
        "hsv_excel_path = '/content/drive/MyDrive/visual titration/v8/data/hsvcodes_masked_segmented_12122024_newdataset.xlsx'\n",
        "\n",
        "# Load the HSV ranges from the Excel file\n",
        "hsv_df = pd.read_excel(hsv_excel_path)\n",
        "\n",
        "# Remove the 'masked_' prefix to match the Excel file\n",
        "corresponding_image_name = image_path.split('/')[-1].replace('masked_', '')\n",
        "\n",
        "# Get the HSV ranges for the current image from the Excel file\n",
        "hsv_row = hsv_df[hsv_df['Image'].str.contains(corresponding_image_name, na=False, case=False)]\n",
        "\n",
        "# Skip if no HSV data is found for the image\n",
        "if hsv_row.empty:\n",
        "    print(f\"No HSV data found for image: {image_path}\")\n",
        "    exit()\n",
        "\n",
        "# Extract HSV ranges\n",
        "h_min, s_min, v_min = hsv_row[['H_min', 'S_min', 'V_min']].values[0]\n",
        "h_max, s_max, v_max = hsv_row[['H_max', 'S_max', 'V_max']].values[0]\n",
        "\n",
        "# Resize the image\n",
        "scale_percent = 60\n",
        "width = int(image.shape[1] * scale_percent / 100)\n",
        "height = int(image.shape[0] * scale_percent / 100)\n",
        "scaled_image = cv2.resize(image, (width, height))\n",
        "\n",
        "# *** For details, contact the repository owner (Mirkan Emir Sancak, mrkn.sancak@gmail.com) ***\n",
        "\n",
        "# Step 1: Apply Sobel Filter for Edge Detection\n",
        "sobel_x = cv2.Sobel(scaled_image, cv2.CV_64F, 1, 0, ksize=5)\n",
        "sobel_y = cv2.Sobel(scaled_image, cv2.CV_64F, 0, 1, ksize=5)\n",
        "edges = cv2.magnitude(sobel_x, sobel_y)\n",
        "edges = np.uint8(edges)\n",
        "\n",
        "# Step 2: Remove Reflections\n",
        "hsv_image = cv2.cvtColor(scaled_image, cv2.COLOR_BGR2HSV)\n",
        "reflection_mask = cv2.inRange(hsv_image, np.array([0, 0, 200]), np.array([180, 255, 255]))  # Detect bright regions\n",
        "cleaned_image = cv2.inpaint(scaled_image, reflection_mask, inpaintRadius=3, flags=cv2.INPAINT_TELEA)\n",
        "\n",
        "# Step 3: Enhance Contrast with CLAHE\n",
        "lab_image = cv2.cvtColor(cleaned_image, cv2.COLOR_BGR2LAB)\n",
        "l, a, b = cv2.split(lab_image)\n",
        "clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
        "l = clahe.apply(l)\n",
        "lab_image = cv2.merge((l, a, b))\n",
        "enhanced_image = cv2.cvtColor(lab_image, cv2.COLOR_LAB2BGR)\n",
        "\n",
        "# Step 4: Bilateral Filtering\n",
        "bilateral_filtered = cv2.bilateralFilter(enhanced_image, 9, 75, 75)\n",
        "\n",
        "# Create a mask to exclude black pixels (assuming black is [0, 0, 0] in BGR)\n",
        "black_mask = cv2.inRange(bilateral_filtered, np.array([1, 1, 1]), np.array([255, 255, 255]))\n",
        "\n",
        "# Apply the mask to the image\n",
        "masked_image = cv2.bitwise_and(bilateral_filtered, bilateral_filtered, mask=black_mask)\n",
        "\n",
        "# Print image processing details\n",
        "print(f\"\\nProcessed Image: {image_path}\")\n",
        "print(\"Processing Steps Completed Successfully.\")\n",
        "\n",
        "# Visualization of different processing steps\n",
        "fig = plt.figure(figsize=(15, 10))\n",
        "\n",
        "# Define labels\n",
        "labels = [\"a)\", \"b)\", \"c)\", \"d)\", \"e)\"]\n",
        "processing_images = [\n",
        "    cv2.cvtColor(scaled_image, cv2.COLOR_BGR2RGB),  # Original Image\n",
        "    edges,  # Sobel Filter Output\n",
        "    cv2.cvtColor(cleaned_image, cv2.COLOR_BGR2RGB),  # Reflection Removal\n",
        "    cv2.cvtColor(enhanced_image, cv2.COLOR_BGR2RGB),  # CLAHE Enhanced Image\n",
        "    cv2.cvtColor(masked_image, cv2.COLOR_BGR2RGB)  # Bilateral Filtered Image\n",
        "]\n",
        "\n",
        "# Create a GridSpec layout\n",
        "gs = gridspec.GridSpec(2, 6, height_ratios=[1, 1])\n",
        "\n",
        "# Row 1: Three images\n",
        "ax1 = plt.subplot(gs[0, 0:2])  # First column\n",
        "ax1.imshow(processing_images[0])\n",
        "ax1.set_title(labels[0], fontsize=18, pad=3)\n",
        "ax1.axis(\"off\")\n",
        "\n",
        "ax2 = plt.subplot(gs[0, 2:4])  # Second column\n",
        "ax2.imshow(processing_images[1], cmap='gray')\n",
        "ax2.set_title(labels[1], fontsize=18, pad=3)\n",
        "ax2.axis(\"off\")\n",
        "\n",
        "ax3 = plt.subplot(gs[0, 4:6])  # Third column\n",
        "ax3.imshow(processing_images[2])\n",
        "ax3.set_title(labels[2], fontsize=18, pad=3)\n",
        "ax3.axis(\"off\")\n",
        "\n",
        "# Row 2: Two images centered\n",
        "ax4 = plt.subplot(gs[1, 1:3])  # First centered column\n",
        "ax4.imshow(processing_images[3])\n",
        "ax4.set_title(labels[3], fontsize=18, pad=3)\n",
        "ax4.axis(\"off\")\n",
        "\n",
        "ax5 = plt.subplot(gs[1, 3:5])  # Second centered column\n",
        "ax5.imshow(processing_images[4])\n",
        "ax5.set_title(labels[4], fontsize=18, pad=3)\n",
        "ax5.axis(\"off\")\n",
        "\n",
        "# Adjust layout\n",
        "plt.tight_layout(pad=1, h_pad=1, w_pad=1)\n",
        "plt.show()\n",
        "\n",
        "# *** For details, contact the repository owner (Mirkan Emir Sancak, mrkn.sancak@gmail.com)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "229ad7e775874317aa31ea04b56c8d1c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "292ce27bce6747f3aba6486fee6849e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d1460f7936c54ed5b0d21e64bca64dc4",
              "IPY_MODEL_a815c1c0a50848a79fa887ec2e297c37",
              "IPY_MODEL_a810e5599d6d42aaa6f89bc9d3d2fdee"
            ],
            "layout": "IPY_MODEL_97ecd6485ad0436392225ba946276bac"
          }
        },
        "3d330cc75e544dc8b5d2c8804c561982": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "45c2cb89728645a6b8ab85f6566d3e76": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6898af0fcc4a4cef9c5692e516d6bef9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e0b8e9e5f64d47cd865ae633fced9ef1",
            "placeholder": "​",
            "style": "IPY_MODEL_94f6af18d5f848d7b6e5071730894ff2",
            "value": "100%"
          }
        },
        "70b9d5b797c0461c9e75c6e5d0f5acb3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "94f6af18d5f848d7b6e5071730894ff2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "97ecd6485ad0436392225ba946276bac": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "98d5fbe5431f47b2af345ef0a84c7b9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3d330cc75e544dc8b5d2c8804c561982",
            "max": 4,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e1d20eb5858146a2abf08fec113aab2d",
            "value": 4
          }
        },
        "a810e5599d6d42aaa6f89bc9d3d2fdee": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ae828bb69fa541b48ef6132a428061da",
            "placeholder": "​",
            "style": "IPY_MODEL_70b9d5b797c0461c9e75c6e5d0f5acb3",
            "value": " 4/4 [00:00&lt;00:00,  5.99it/s]"
          }
        },
        "a815c1c0a50848a79fa887ec2e297c37": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e5f5c56b1a0640dc93685a4786c888ff",
            "max": 4,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_45c2cb89728645a6b8ab85f6566d3e76",
            "value": 4
          }
        },
        "ac33b4be5a8b4e86bfd9379e06566ae3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_229ad7e775874317aa31ea04b56c8d1c",
            "placeholder": "​",
            "style": "IPY_MODEL_b9cd0ba5f1b54608bd5a4d19b989d51f",
            "value": " 4/4 [00:00&lt;00:00,  7.23it/s]"
          }
        },
        "ae828bb69fa541b48ef6132a428061da": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b9cd0ba5f1b54608bd5a4d19b989d51f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bb02e3c86e3b49278170f32ffbaf1510": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cdd464ceba884e479da5532190e3dcfe": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6898af0fcc4a4cef9c5692e516d6bef9",
              "IPY_MODEL_98d5fbe5431f47b2af345ef0a84c7b9f",
              "IPY_MODEL_ac33b4be5a8b4e86bfd9379e06566ae3"
            ],
            "layout": "IPY_MODEL_d130547d9eb94159bfaead2d2dcb3754"
          }
        },
        "d130547d9eb94159bfaead2d2dcb3754": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d1460f7936c54ed5b0d21e64bca64dc4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f8d414dc50724a8ab7d7c0955ee77fe9",
            "placeholder": "​",
            "style": "IPY_MODEL_bb02e3c86e3b49278170f32ffbaf1510",
            "value": "100%"
          }
        },
        "e0b8e9e5f64d47cd865ae633fced9ef1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e1d20eb5858146a2abf08fec113aab2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e5f5c56b1a0640dc93685a4786c888ff": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f8d414dc50724a8ab7d7c0955ee77fe9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
